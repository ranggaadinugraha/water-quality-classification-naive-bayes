{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1VhSdLOP11dcfnfO2+bPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranggaadinugraha/water-quality-classification-naive-bayes/blob/main/water_quality_naive_bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Water Quality Classification using Naive Bayes & Cross Validation\n",
        "## This project aims to classify water quality (Safe / Not Safe) based on chemical parameters using the Naive Bayes algorithm."
      ],
      "metadata": {
        "id": "TbOVlj1x4UDQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "dMPNMMq_qqPf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPBRixWx3NlL"
      },
      "outputs": [],
      "source": [
        "# Import Libraries for Data Processing\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries for Data Visualization\n",
        "import plotly.figure_factory as ff\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "-q7vL8PT3Z1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries for Machine Learning & Evaluation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "e4zNOo-F3dfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· LOAD DATASET"
      ],
      "metadata": {
        "id": "HaRl-43oqu71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Water Quality Dataset\n",
        "df = pd.read_csv('waterQuality1.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "53qOlguu3dic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· EXPLORATORY DATA ANALYSIS (EDA)"
      ],
      "metadata": {
        "id": "Jl50iQW5q6pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Dataset Overview\n",
        "df.info()"
      ],
      "metadata": {
        "id": "4odVAMHL3dlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Missing Values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "BzGyevx83dno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· DATA SELECTION & PREPARATION"
      ],
      "metadata": {
        "id": "nFGvirhtrKqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limit Dataset Size for Faster Processing\n",
        "# Separate Features (X) and Target Variable (Y)\n",
        "# Target : is_safe\n",
        "df = df[:1000]\n",
        "Y = df.iloc[:,20]\n",
        "X = df.drop(['ammonia', 'is_safe'], axis=1)"
      ],
      "metadata": {
        "id": "Md-MIoEy3lW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "4J5l_BhW3lZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "id": "3LugmSvn3lcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· TRAIN-TEST SPLIT"
      ],
      "metadata": {
        "id": "U9JCMmtrrWbI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Dataset into Training and Testing Sets\n",
        "X_latih, X_tes, Y_latih, Y_tes = train_test_split(X,\n",
        "                                                  Y,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=1)"
      ],
      "metadata": {
        "id": "a_zUuhIb3le7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Dataset Split Information\n",
        "print('Data X Latih:', len(X_latih))\n",
        "print('Data Y Latih:', len(Y_latih))\n",
        "print('Data X Testing:', len(X_tes))\n",
        "print('Data Y Testing:', len(X_tes))"
      ],
      "metadata": {
        "id": "13e335YX3lhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· MODEL DEVELOPMENT â€“ NAIVE BAYES"
      ],
      "metadata": {
        "id": "XsCCU-Ccrex8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train Gaussian Naive Bayes Model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(X_latih, Y_latih)\n",
        "\n",
        "# Make Predictions on Test Data\n",
        "Y_pred = gnb.predict(X_tes)"
      ],
      "metadata": {
        "id": "bAdJMYh_3lj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Model Accuracy\n",
        "print(\"Model Accuracy : \",accuracy_score(Y_tes, Y_pred))"
      ],
      "metadata": {
        "id": "U20xg5xp3wzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "825hCnH2ryFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Confusion Matrix\n",
        "gnb_cf = confusion_matrix(Y_tes, Y_pred)"
      ],
      "metadata": {
        "id": "EKNwQQeC3w2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb_cf"
      ],
      "metadata": {
        "id": "CVRdIWLq3w4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Visualize Confusion Matrix\n",
        "def plot_cm(matrix, title):\n",
        "  z = matrix\n",
        "  x = ['Safe', 'Not']\n",
        "  y = x\n",
        "\n",
        "  z_text = [[str(y) for y in x] for x in z]\n",
        "  z_text.reverse()\n",
        "\n",
        "  fig = ff.create_annotated_heatmap(z, x=x, y=y,\n",
        "                                    annotation_text=z_text,\n",
        "                                    colorscale='blugrn')\n",
        "\n",
        "  fig.update_layout(\n",
        "      title_text='<i><b>Confusion matrix {}</b></i>'.format(title))\n",
        "\n",
        "  fig.add_annotation({'font':{'color':\"black\",'size':14},\n",
        "                            'x':0.5,\n",
        "                            'y':-0.1,\n",
        "                            'showarrow':False,\n",
        "                            'text':\"\",\n",
        "                            'xref':\"paper\",\n",
        "                            'yref':\"paper\"})\n",
        "\n",
        "  fig.add_annotation({'font':{'color':\"black\",'size':14},\n",
        "                            'x':-0.20,\n",
        "                            'y':0.5,\n",
        "                            'showarrow':False,\n",
        "                            'text':\"\",\n",
        "                            'textangle':-90,\n",
        "                            'xref':\"paper\",\n",
        "                            'yref':\"paper\"})\n",
        "\n",
        "\n",
        "  fig.update_layout(margin={'t':50, 'l':20},width=500,height=500)\n",
        "\n",
        "  fig['data'][0]['showscale'] = True\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "3xDjYNBb3w7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display Confusion Matrix\n",
        "plot_cm(gnb_cf, title=\"model\")"
      ],
      "metadata": {
        "id": "svqv9kTr32zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· CLASSIFICATION REPORT"
      ],
      "metadata": {
        "id": "LyDiy38nr9wG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Classification Report\n",
        "nb_report = classification_report(Y_tes, Y_pred,\n",
        "                                  output_dict=True,\n",
        "                                  target_names=['Safe','Not'])\n",
        "pd.DataFrame(nb_report).transpose()"
      ],
      "metadata": {
        "id": "BpTKdAMb321o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· MODEL PERFORMANCE SUMMARY"
      ],
      "metadata": {
        "id": "QlOWQWsysF6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Performance Metrics Table\n",
        "metrics = pd.DataFrame({'accuracy' : [nb_report['accuracy']],\n",
        "                        'precision_0' : [nb_report['Safe']['precision']],\n",
        "                        'recall_0' : [nb_report['Safe']['recall']],\n",
        "                        'f1-score_0' : [nb_report['Safe']['f1-score']],\n",
        "                        'precision_1' : [nb_report['Not']['precision']],\n",
        "                        'recall_1' : [nb_report['Not']['recall']],\n",
        "                        'f1-score_1' : [nb_report['Not']['f1-score']]},\n",
        "                        index=['Naive Bayes Classifier'])\n",
        "multiheader = [('','accuracy'),\n",
        "               ('Safe', 'precision'),\n",
        "               ('Safe', 'recall'),\n",
        "               ('Safe', 'f1-score'),\n",
        "               ('Not', 'precision'),\n",
        "               ('Not', 'recall'),\n",
        "               ('Not', 'f1-score')]\n",
        "metrics.columns = pd.MultiIndex.from_tuples(multiheader)\n",
        "metrics"
      ],
      "metadata": {
        "id": "IArn7i8H323s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· CROSS-VALIDATION"
      ],
      "metadata": {
        "id": "qWU_S3YqsI_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Pipeline with Standardization and Naive Bayes\n",
        "pipeline = make_pipeline(StandardScaler(),\n",
        "    GaussianNB(priors=None))"
      ],
      "metadata": {
        "id": "8g0d8ldu36_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified K-Fold Cross Validation\n",
        "# Perform Cross Validation\n",
        "# Display Cross Validation Result\n",
        "strtfdkFold = StratifiedKFold(n_splits=10)\n",
        "kfold = strtfdkFold.split(X_latih, Y_latih)\n",
        "scores =[]\n",
        "for k, (train, test) in enumerate(kfold):\n",
        "  pipeline.fit(X_latih.iloc[train, :], Y_latih.iloc[train])\n",
        "  score = pipeline.score(X_latih.iloc[test, :],\n",
        "                         Y_latih.iloc[test])\n",
        "\n",
        "  scores.append(score)\n",
        "  print('Fold: %2d, Training/Test Split Distributiomn: %s, Accuracy: %.3f' % (\n",
        "      k+1, np.bincount(Y_latih.iloc[train]),score))\n",
        "\n",
        "  print('\\n\\nCross-Validation accuracy: %.3f +\\- %.3f'%(\n",
        "      np.mean(scores), np.std(scores)))\n"
      ],
      "metadata": {
        "id": "u8g5sY3Q37CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”· CROSS-VALIDATION VISUALIZATION"
      ],
      "metadata": {
        "id": "Aj4HQP8XsaeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize Cross Validation Accuracy\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "y_axis = scores\n",
        "sns.lineplot(y_axis)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DHIhnlcq3_4V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}